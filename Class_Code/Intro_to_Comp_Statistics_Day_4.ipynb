{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zd7twlpjU2Et"
      ],
      "mount_file_id": "1YxSM6RB1KBp8I2n-swOwvLm88M2-nwfs",
      "authorship_tag": "ABX9TyNdtU/8EZgbJazPbuBpxG8z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stswee/IntroCompStatsHSSP2023/blob/main/Class_Code/Intro_to_Comp_Statistics_Day_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Computational Statistics (HSSP 2023 Edition)\n",
        "## Day 4: Bootstrapping and Data Analysis\n",
        "\n",
        "In this notebook, we will run bootstrapping programs and perform basic data analysis."
      ],
      "metadata": {
        "id": "rjrXxcMa07Iv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Activity 1: Rolling 2 Dice"
      ],
      "metadata": {
        "id": "zd7twlpjU2Et"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement:\n",
        "\n",
        "You roll two four-sided dice and you want to see if there is a correlation between the rolls. You gather the following data:"
      ],
      "metadata": {
        "id": "Yfh733kHU7ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array([[15, 28, 30, 12], [22, 41, 10, 8], [30, 42, 28, 19], [31, 20, 10, 10]])\n",
        "print(data)"
      ],
      "metadata": {
        "id": "weQCLn9IVU7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each element can be thought of as a coordinate. For example, the 12 on the top right is (1, 4). This reflects the number of times we rolled 1 on the first dice and 4 on the second."
      ],
      "metadata": {
        "id": "kQWfDE8HVjWV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the exact and estimated (bootstrap) p-value."
      ],
      "metadata": {
        "id": "6uJTwwdPWD4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# By hand calculations\n",
        "# Initialize totals\n",
        "row_total = np.zeros(data.shape[0])\n",
        "column_total = np.zeros(data.shape[1])\n",
        "sample_size = sum(sum(data))\n",
        "\n",
        "for i in range(len(row_total)):\n",
        "  row_total[i] = sum(data[i,:])\n",
        "\n",
        "for j in range(len(column_total)):\n",
        "  column_total[j] = sum(data[:, j])\n",
        "\n",
        "print(sample_size)\n",
        "\n",
        "# Alternatively, for column total, can use the code below\n",
        "# column_total = sum(data)\n",
        "\n",
        "# Determine expected counts array\n",
        "expected_counts = np.zeros(data.shape)\n",
        "\n",
        "for i in range(len(row_total)):\n",
        "  for j in range(len(column_total)):\n",
        "    expected_counts[i, j] = row_total[i] * column_total[j] / sample_size\n",
        "\n",
        "# Calculate chi-square test statistic\n",
        "test_statistic = 0\n",
        "for i in range(data.shape[0]):\n",
        "  for j in range(data.shape[1]):\n",
        "    test_statistic += (data[i, j] - expected_counts[i,j])**2 / (expected_counts[i, j])\n",
        "\n",
        "# Determine degrees of freedom\n",
        "df = (data.shape[0] - 1) * (data.shape[1] - 1)\n",
        "\n",
        "# Determine p-value\n",
        "pval = 1 - chi2.cdf(test_statistic, df, loc=0, scale=1)\n",
        "\n",
        "print('Test statistic is : ' + str(test_statistic))\n",
        "print('p value : ' + str(pval))"
      ],
      "metadata": {
        "id": "igq1FR8FWr2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using stats package\n",
        "test_statistic, pval = stats.chi2_contingency(data)[0:2]\n",
        "print('Test statistic is : ' + str(test_statistic))\n",
        "print('p value : ' + str(pval))"
      ],
      "metadata": {
        "id": "JIYABquxWJPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bootstrap\n",
        "# Initialize totals\n",
        "row_total = np.zeros(data.shape[0])\n",
        "column_total = np.zeros(data.shape[1])\n",
        "sample_size = sum(sum(data))\n",
        "\n",
        "for i in range(len(row_total)):\n",
        "  row_total[i] = sum(data[i,:])\n",
        "\n",
        "for j in range(len(column_total)):\n",
        "  column_total[j] = sum(data[:, j])\n",
        "\n",
        "# Estimate null distribution\n",
        "row_dist = row_total / sum(row_total)\n",
        "column_dist = column_total / sum(column_total)"
      ],
      "metadata": {
        "id": "LPSDEd-BY4Hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function definition to draw from distribution\n",
        "def draw_integers(integers, probabilities, n):\n",
        "    random_integers = random.choices(integers, probabilities, k = n)\n",
        "    return random_integers"
      ],
      "metadata": {
        "id": "jkc1rLNQhCFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run bootstrap\n",
        "B = 10000 # Number of samples (for B = 10000, about 90 seconds)\n",
        "\n",
        "# Storage for array of test statistics\n",
        "boot_test_statistics = np.empty(B)\n",
        "\n",
        "for b in range(B):\n",
        "  # Draw from estimated null distribution\n",
        "  x = np.array(draw_integers([1, 2, 3, 4], row_dist, sample_size))\n",
        "  y = np.array(draw_integers([1, 2, 3, 4], column_dist, sample_size))\n",
        "\n",
        "  # Get contingency table\n",
        "  boot_contingency_table = np.histogram2d(x, y, bins=[np.max(x), np.max(y)])[0]\n",
        "\n",
        "  # Calculate test statistic\n",
        "  boot_test_statistic = stats.chi2_contingency(boot_contingency_table)[0]\n",
        "\n",
        "  # Store test statistic\n",
        "  boot_test_statistics[i] = boot_test_statistic\n",
        "\n",
        "# Bootstrap p-value\n",
        "pval = (sum(boot_test_statistics > test_statistic) + 1)/ (B + 1)\n",
        "print(pval)"
      ],
      "metadata": {
        "id": "cb3Qh9AjhH0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Activity 2: Performing Data Analysis"
      ],
      "metadata": {
        "id": "jJYx313F3zxt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Research Question: Is there a statistically significant association between gender, education level, and years of experience with salary?"
      ],
      "metadata": {
        "id": "jU-74GQr35eS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting Dataset from Kaggle:\n",
        "\n",
        "1. Sign in to Kaggle (make a free account if you have not already)\n",
        "\n",
        "2. Go to https://www.kaggle.com/datasets/mohithsairamreddy/salary-data and download the dataset\n",
        "\n",
        "3. Unzip the file and load dataset into Google Colab"
      ],
      "metadata": {
        "id": "DMBSt9udC8-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.formula.api as sm\n",
        "from scipy.stats import norm\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning) # Suppress warnings"
      ],
      "metadata": {
        "id": "hdyBJlIiDLgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in data\n",
        "df = pd.read_csv(\"Salary_Data.csv\")\n",
        "\n",
        "# Rename columns\n",
        "df = df.rename(columns = {\"Education Level\" : \"Education\", \"Years of Experience\" : \"Experience\"})\n",
        "\n",
        "# Clean data\n",
        "df = df.dropna()\n",
        "df.loc[df['Education'] == \"Bachelor's\", 'Education'] = \"Master's Degree\"\n",
        "df.loc[df['Education'] == \"Master's\", 'Education'] = \"Master's Degree\"\n",
        "df.loc[df['Education'] == \"phD\", 'Education'] = \"PhD\"\n",
        "\n",
        "# Print unique values for categorical variables\n",
        "print(df['Gender'].unique())\n",
        "print(df['Education'].unique())"
      ],
      "metadata": {
        "id": "8SCvxfD_Xtai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View first 5 rows of dataset\n",
        "df.head()"
      ],
      "metadata": {
        "id": "tBtuYuquY1rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will perform ordinary least-squares regression (similar to simple linear regression) using all of the datapoints. We will then calculate the confidence intervals for the slope."
      ],
      "metadata": {
        "id": "0eqfOqesXy7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform simple linear regression\n",
        "ols_model = sm.ols(formula = 'Salary ~ Gender + Education + Experience', data = df)\n",
        "results = ols_model.fit()\n",
        "\n",
        "# Display results\n",
        "print(\"Intercept: \", results.params[0])\n",
        "print()\n",
        "print(\"Gender Slope:\\n\", format(results.params[1:3]))\n",
        "print()\n",
        "print(\"Education Slope:\\n\", format(results.params[3:6]))\n",
        "print()\n",
        "print(\"Years Slope:\\n\", format(results.params[6]))\n",
        "print()"
      ],
      "metadata": {
        "id": "jmyLD7jIYeMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot\n",
        "# Adjust these values\n",
        "gender = \"Male\"\n",
        "education = \"PhD\"\n",
        "\n",
        "# Select actual values and make predictions\n",
        "data = df[(df['Gender'] == gender) & (df[\"Education\"] == education)]\n",
        "x = data.iloc[:, :-1]\n",
        "y_actual = data.iloc[:, -1]\n",
        "y_pred = ols_model.fit().predict(x)\n",
        "\n",
        "# Plot results\n",
        "plt.scatter(x['Experience'], y_actual)\n",
        "plt.plot(x['Experience'], y_pred, linewidth = 1, color = \"red\")\n",
        "plt.xlabel(\"Years\")\n",
        "plt.ylabel(\"Salary\")\n",
        "plt.title(\"Gender = \" + gender + \", Education = \" + education)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vP75-_o3civc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intercept and Slope 95% confidence intervals\n",
        "results.conf_int(alpha = 0.05)"
      ],
      "metadata": {
        "id": "NF8Lu92ajfmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will use bootstrapping to sample a portion of the data and fit its respective slopes. Let's start with getting one sample."
      ],
      "metadata": {
        "id": "Q7vK-ANkkH_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample a portion of the dataset\n",
        "size_percentage = 0.5\n",
        "sample = df.sample(n = int(df.shape[0]*size_percentage), replace = True)\n",
        "\n",
        "# Perform linear regression on sample\n",
        "ols_model_boot = sm.ols(formula = 'Salary ~ Gender + Education + Experience', data = sample)\n",
        "results_boot = ols_model_boot.fit()\n",
        "\n",
        "# Display results\n",
        "print(\"Intercept: \", results_boot.params[0])\n",
        "print()\n",
        "print(\"Gender Slope:\\n\", format(results_boot.params[1:3]))\n",
        "print()\n",
        "print(\"Education Slope:\\n\", format(results_boot.params[3:6]))\n",
        "print()\n",
        "print(\"Years Slope:\\n\", format(results_boot.params[6]))\n",
        "print()"
      ],
      "metadata": {
        "id": "Av6tB-2NkHMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you were to rerun the code above, you will get a different value every time. We can make the results reproducible by setting a seed. This is done by setting the random_state parameter to a particular value."
      ],
      "metadata": {
        "id": "q3QvjMADgzLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample a portion of the dataset\n",
        "size_percentage = 0.5\n",
        "sample = df.sample(n = int(df.shape[0]*size_percentage), replace = True, random_state = 0)\n",
        "\n",
        "# Perform linear regression on sample\n",
        "ols_model_boot = sm.ols(formula = 'Salary ~ Gender + Education + Experience', data = sample)\n",
        "results_boot = ols_model_boot.fit()\n",
        "\n",
        "# Display results\n",
        "print(\"Intercept: \", results_boot.params[0])\n",
        "print()\n",
        "print(\"Gender Slope:\\n\", format(results_boot.params[1:3]))\n",
        "print()\n",
        "print(\"Education Slope:\\n\", format(results_boot.params[3:6]))\n",
        "print()\n",
        "print(\"Years Slope:\\n\", format(results_boot.params[6]))\n",
        "print()"
      ],
      "metadata": {
        "id": "nMAezrycg94q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To generate the bootstrap 95% confidence interval and display a histogram of our results, we can first create an array to store the results. Then, we can sample from our dataset, perform a fit, and record the results. Finally, we can plot the results and compute the confidence interval."
      ],
      "metadata": {
        "id": "Uk6CiWnmhLe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataframe to store results\n",
        "boot_results = pd.DataFrame({'Intercept' : [], 'Gender[T.Male]' : [], 'Gender[T.Other]' : [], 'Education[T.High School]' : [],\n",
        "                             \"Education[T.Master's Degree]\" : [], 'Education[T.PhD]' : [], 'Experience' : []})\n",
        "\n",
        "# Number of iterations\n",
        "B = 1000 # (1000 takes about 45 seconds to run, 10000 about 6 minutes)\n",
        "\n",
        "# Perform bootstrapping\n",
        "for b in range(B):\n",
        "\n",
        "  # Sample a portion of the dataset\n",
        "  size_percentage = 0.5\n",
        "  sample = df.sample(n = int(df.shape[0]*size_percentage), replace = True, random_state = b) # Set random state to b for reproducibility\n",
        "\n",
        "  # Perform linear regression on sample\n",
        "  ols_model_boot = sm.ols(formula = 'Salary ~ Gender + Education + Experience', data = sample)\n",
        "  results_boot = ols_model_boot.fit()\n",
        "\n",
        "  # Append results\n",
        "  boot_results = boot_results.append(results_boot.params[0:7], ignore_index = True)\n",
        "\n",
        "  # Keep track of progress for every 100 iterations\n",
        "  if (b % 100 == 0):\n",
        "    print(b)"
      ],
      "metadata": {
        "id": "-nrCNJ_Zhblc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic histogram of intercept\n",
        "plt.hist(boot_results.iloc[:,0])\n",
        "plt.xlabel(boot_results.columns[0])\n",
        "plt.ylabel(\"Frequency\")"
      ],
      "metadata": {
        "id": "dzDtOCfKmT6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code generated by ChatGPT\n",
        "def plot_histogram_with_fit(data, num_bins=10, xlabel=None, ylabel=None, title=None):\n",
        "    \"\"\"\n",
        "    Plots a histogram with a normal distribution fit overlay.\n",
        "\n",
        "    Parameters:\n",
        "        data (list or numpy array): The input data for the histogram and fit.\n",
        "        num_bins (int): Number of bins for the histogram. Default is 10.\n",
        "        xlabel (str): Label for the x-axis. Default is None.\n",
        "        ylabel (str): Label for the y-axis. Default is None.\n",
        "        title (str): Title for the plot. Default is None.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Create the histogram\n",
        "    n, bins, patches = plt.hist(data, bins=num_bins, alpha=0.7, edgecolor='black', color='skyblue')\n",
        "\n",
        "    # Get the mean and standard deviation of the data\n",
        "    mean = np.mean(data)\n",
        "    std = np.std(data)\n",
        "\n",
        "    # Generate normal distribution data points for the overlay\n",
        "    x = np.linspace(min(data), max(data), 100)\n",
        "    y = norm.pdf(x, mean, std) * len(data) * (bins[1] - bins[0])  # Scaling to match the histogram\n",
        "\n",
        "    # Plot the normal distribution fit\n",
        "    plt.plot(x, y, 'r-', label='Normal Fit')\n",
        "\n",
        "    # Set labels and title\n",
        "    if xlabel:\n",
        "        plt.xlabel(xlabel)\n",
        "    if ylabel:\n",
        "        plt.ylabel(ylabel)\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "\n",
        "    # Show the plot with the legend\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_histogram_with_fit(boot_results.iloc[:,0], num_bins=10, xlabel=boot_results.columns[0], ylabel='Frequency', title='Distribution of ' + boot_results.columns[0])\n"
      ],
      "metadata": {
        "id": "UMLoooHupYe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot all histograms\n",
        "for i in range(boot_results.shape[1]):\n",
        "  plot_histogram_with_fit(boot_results.iloc[:,i], num_bins=10, xlabel=boot_results.columns[i], ylabel='Frequency', title='Distribution of ' + boot_results.columns[i])\n"
      ],
      "metadata": {
        "id": "_hsmVignqAfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate confidence intervals\n",
        "# Select significance level\n",
        "alpha = 0.05\n",
        "\n",
        "for i in range(boot_results.shape[1]):\n",
        "  print(str(round(1 - alpha, 2)*100) + \"% Confidence interval for \" + str(boot_results.columns[i]) + \": [\" +\n",
        "  str(np.nanpercentile(boot_results.iloc[:,i], alpha/2 * 100)) + \", \" +\n",
        "  str(np.nanpercentile(boot_results.iloc[:,i], 100 - alpha/2 * 100)) + \"]\")\n",
        "\n",
        "# Compare with original result\n",
        "# Intercept and Slope 95% confidence intervals\n",
        "results.conf_int(alpha)"
      ],
      "metadata": {
        "id": "U58La1JlqOMs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}